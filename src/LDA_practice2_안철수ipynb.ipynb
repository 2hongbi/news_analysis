{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_practice2_안철수ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cC5GwAKwo3CZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31lMlebGMh7p",
        "outputId": "99011b20-e05b-4a1c-dab1-459b066ac0bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwzT-j9sNI7k"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UUI53c6YNJES",
        "outputId": "01cc65d5-5b1a-4f6c-dfc1-7724ab95f725"
      },
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/outlier/안철수.csv\")\n",
        "data.head()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>date</th>\n",
              "      <th>retweets_count</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>현 정부용어사전 55 2012년 20대 2010년에 중학교를 다닌 사람 용례 서병수...</td>\n",
              "      <td>2021-11-22</td>\n",
              "      <td>0</td>\n",
              "      <td>https://twitter.com/MB_DIC/status/146277899140...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>escrimeurk 왜 부정적으로 봐요 국민들한테 이익이되는 일에는 좌 우를 따질...</td>\n",
              "      <td>2021-11-22</td>\n",
              "      <td>0</td>\n",
              "      <td>https://twitter.com/sbwlffosem0930/status/1462...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>illi1ilIIll1i 예전 정의당 통진당애들이 저런소리 많이했죠 안철수 지지자들도</td>\n",
              "      <td>2021-11-22</td>\n",
              "      <td>0</td>\n",
              "      <td>https://twitter.com/onlymoon111/status/1462778...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hibiscus0919 맞네요</td>\n",
              "      <td>2021-11-22</td>\n",
              "      <td>0</td>\n",
              "      <td>https://twitter.com/sbwlffosem0930/status/1462...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>윤석열은 아니죠 반사적우로 이야기하고 아차 싶어서 이재명도 별로고 영 찍을 사람 없...</td>\n",
              "      <td>2021-11-22</td>\n",
              "      <td>0</td>\n",
              "      <td>https://twitter.com/wannabehumann/status/14627...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  ...                                               link\n",
              "0  현 정부용어사전 55 2012년 20대 2010년에 중학교를 다닌 사람 용례 서병수...  ...  https://twitter.com/MB_DIC/status/146277899140...\n",
              "1   escrimeurk 왜 부정적으로 봐요 국민들한테 이익이되는 일에는 좌 우를 따질...  ...  https://twitter.com/sbwlffosem0930/status/1462...\n",
              "2   illi1ilIIll1i 예전 정의당 통진당애들이 저런소리 많이했죠 안철수 지지자들도   ...  https://twitter.com/onlymoon111/status/1462778...\n",
              "3                                   hibiscus0919 맞네요  ...  https://twitter.com/sbwlffosem0930/status/1462...\n",
              "4  윤석열은 아니죠 반사적우로 이야기하고 아차 싶어서 이재명도 별로고 영 찍을 사람 없...  ...  https://twitter.com/wannabehumann/status/14627...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ariILWYSROAS",
        "outputId": "b2db86d0-53b7-4b63-ad84-f9f2b000ea14"
      },
      "source": [
        "range(len(data[\"tweet\"])) #4405개 데이터"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 4405)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGT7SVb6Z-FV"
      },
      "source": [
        "# 정수 인코딩과 단어 집합 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuBJuni0mBgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5be163-1ae8-4a74-d36e-dbcf14041c13"
      },
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Kkma  \n",
        "kkma = Kkma()\n",
        "tokenized_doc=[]\n",
        "for n in range(len(data[\"tweet\"])):\n",
        "    text = data[\"tweet\"][n]\n",
        "    tokenized_doc.append(list(kkma.nouns(str(text))))\n",
        "print(tokenized_doc[:5])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "[['현', '정부', '정부용어사전', '용어', '사전', '55', '2012', '2012년', '년', '20', '20대', '대', '2010', '2010년', '중학교', '사람', '용례', '병수', '안', '안철수', '철수', '지지', '교과서', '영향', '기술', '기술교과서', '건'], ['부정적', '국민', '이익', '일', '좌', '우', '이유', '철수', '실용', '실용주의자지', '주의', '자지', '보수', '이상'], ['1', '예전', '정의', '정의당', '당', '통', '통진당애', '진', '애', '소리', '철수', '지지자'], ['0919'], ['윤', '열', '반사적', '반사적우로', '우로', '이야기', '이재명', '고', '영', '사람', '랬', '철수']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eyhPd0DLUGA",
        "outputId": "767efd2b-1198-445b-d0ae-8b8f4a1ca185"
      },
      "source": [
        "print(tokenized_doc[2])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '예전', '정의', '정의당', '당', '통', '통진당애', '진', '애', '소리', '철수', '지지자']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3BNulWFcDhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d669fb11-3195-4aba-ed4b-56c01894e957"
      },
      "source": [
        "kkma.nouns(data[\"tweet\"][2])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '예전', '정의', '정의당', '당', '통', '통진당애', '진', '애', '소리', '철수', '지지자']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEt0fcMOWqHH"
      },
      "source": [
        "이제 각 단어에 정수 인코딩을 하는 동시에, 각 뉴스에서의 단어의 빈도수를 기록. 여기서는 각 단어를 (word_id, word_frequency)의 형태로 바꾸고자 합니다. word_id는 단어가 정수 인코딩된 값이고, word_frequency는 해당 뉴스에서의 해당 단어의 빈도수를 의미합니다. 이는 gensim의 corpora.Dictionary()를 사용하여 손쉽게 구할 수 있습니다. 전체 뉴스에 대해서 정수 인코딩을 수행하고, 세번째 댓글을 추출합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEpT2qdmUUtp",
        "outputId": "fd84a67c-50d9-4ddd-898e-bd2a17fd2e12"
      },
      "source": [
        "from gensim import corpora\n",
        "dictionary = corpora.Dictionary(tokenized_doc)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
        "print(corpus[2])#세번째 댓글 출력"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(25, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z55tIoPwnZi3",
        "outputId": "61bb339d-185e-4ba8-cd25-751b494f7b5c"
      },
      "source": [
        "tokenized_doc[:10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['현',\n",
              "  '정부',\n",
              "  '정부용어사전',\n",
              "  '용어',\n",
              "  '사전',\n",
              "  '55',\n",
              "  '2012',\n",
              "  '2012년',\n",
              "  '년',\n",
              "  '20',\n",
              "  '20대',\n",
              "  '대',\n",
              "  '2010',\n",
              "  '2010년',\n",
              "  '중학교',\n",
              "  '사람',\n",
              "  '용례',\n",
              "  '병수',\n",
              "  '안',\n",
              "  '안철수',\n",
              "  '철수',\n",
              "  '지지',\n",
              "  '교과서',\n",
              "  '영향',\n",
              "  '기술',\n",
              "  '기술교과서',\n",
              "  '건'],\n",
              " ['부정적',\n",
              "  '국민',\n",
              "  '이익',\n",
              "  '일',\n",
              "  '좌',\n",
              "  '우',\n",
              "  '이유',\n",
              "  '철수',\n",
              "  '실용',\n",
              "  '실용주의자지',\n",
              "  '주의',\n",
              "  '자지',\n",
              "  '보수',\n",
              "  '이상'],\n",
              " ['1', '예전', '정의', '정의당', '당', '통', '통진당애', '진', '애', '소리', '철수', '지지자'],\n",
              " ['0919'],\n",
              " ['윤', '열', '반사적', '반사적우로', '우로', '이야기', '이재명', '고', '영', '사람', '랬', '철수'],\n",
              " ['1',\n",
              "  '불',\n",
              "  '여론',\n",
              "  '여론조사',\n",
              "  '조사',\n",
              "  '업체',\n",
              "  '과',\n",
              "  '과태',\n",
              "  '태',\n",
              "  '물고',\n",
              "  '산',\n",
              "  '우호적',\n",
              "  '기관',\n",
              "  '한거잖아',\n",
              "  '실제',\n",
              "  '정도',\n",
              "  '윤',\n",
              "  '윤부적',\n",
              "  '부적',\n",
              "  '5',\n",
              "  '거'],\n",
              " ['선',\n",
              "  '대한',\n",
              "  '대한민국',\n",
              "  '민국',\n",
              "  '혁신',\n",
              "  '논쟁',\n",
              "  '북',\n",
              "  '북콘서트',\n",
              "  '콘서트',\n",
              "  '약자',\n",
              "  '청년',\n",
              "  '꿈',\n",
              "  '공유',\n",
              "  '미래',\n",
              "  '논의',\n",
              "  '2030',\n",
              "  '2030청년',\n",
              "  '과의',\n",
              "  '통장',\n",
              "  '의미',\n",
              "  '국민',\n",
              "  '국민상자',\n",
              "  '상자',\n",
              "  '당',\n",
              "  '안',\n",
              "  '안철수',\n",
              "  '철수',\n",
              "  '4',\n",
              "  '0'],\n",
              " ['혹', '만약', '김', '길', '꼰대', '철수', '대선', '대선포기', '포기', '윤', '꼬붕'],\n",
              " ['안', '안철수', '철수', '겨울', '철새', '왓', '매', '한마디', '천박', '1'],\n",
              " ['0', '10', '공백', '안', '안철수', '철수']]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaLZxwbuX7Tz",
        "outputId": "e5507c1d-3f8b-4596-8042-b81cf642c87f"
      },
      "source": [
        "print(corpus[2])#30개의 댓글 출력"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(25, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frpWRBVAZwQN"
      },
      "source": [
        "총 학습된 단어의 개수를 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdy_pK3VX-31",
        "outputId": "872a6eeb-0766-4740-c1c5-90b1ad69e15d"
      },
      "source": [
        "len(dictionary) #12075개 단어가 학습"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12075"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV8BPIGJZ6qI"
      },
      "source": [
        "#  LDA 모델을 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCpRIwQ4gn6R"
      },
      "source": [
        "각 단어 앞에 붙은 수치는 단어의 해당 토픽에 대한 기여도를 보여줍니다. 또한 맨 앞에 있는 토픽 번호는 0부터 시작하므로 총 20개의 토픽은 0부터 19까지의 번호가 할당되어져 있습니다. passes는 알고리즘의 동작 횟수를 말하는데, 알고리즘이 결정하는 토픽의 값이 적절히 수렴할 수 있도록 충분히 적당한 횟수를 정해주면 됩니다. 여기서는 총 15회를 수행하였습니다. 여기서는 num_words=4로 총 4개의 단어만 출력하도록 하였습니다. 만약 10개의 단어를 출력하고 싶다면 아래의 코드를 수행하면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOeH2soeHTx3"
      },
      "source": [
        "### 토픽번호별 키워드중요도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqssrIHyW3sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47189ae3-4df9-4764-d692-fe5cffb61d40"
      },
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 20 #20개의 토픽(카테고리), k=20\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=7)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "(1, '0.033*\"철수\" + 0.030*\"특검\" + 0.025*\"안\" + 0.022*\"안철수\" + 0.021*\"쌍\" + 0.017*\"쌍특검\" + 0.017*\"경제\"')\n",
            "(2, '0.030*\"철수\" + 0.025*\"국\" + 0.020*\"윤\" + 0.016*\"힘\" + 0.013*\"후보\" + 0.013*\"당\" + 0.012*\"문\"')\n",
            "(3, '0.017*\"철수\" + 0.016*\"양보\" + 0.016*\"정치\" + 0.015*\"우리\" + 0.015*\"21\" + 0.013*\"거\" + 0.012*\"때문\"')\n",
            "(4, '0.023*\"철수\" + 0.022*\"안\" + 0.021*\"안철수\" + 0.011*\"속\" + 0.008*\"수능\" + 0.008*\"1\" + 0.007*\"검찰\"')\n",
            "(5, '0.022*\"철수\" + 0.015*\"너\" + 0.009*\"새끼\" + 0.008*\"수면\" + 0.007*\"동안\" + 0.006*\"나\" + 0.006*\"그\"')\n",
            "(6, '0.017*\"철수\" + 0.015*\"안\" + 0.012*\"3\" + 0.012*\"안철수\" + 0.010*\"청년공약\" + 0.010*\"데일리\" + 0.010*\"대선\"')\n",
            "(7, '0.023*\"철수\" + 0.016*\"킹\" + 0.015*\"1\" + 0.014*\"루\" + 0.014*\"루킹\" + 0.013*\"기술\" + 0.012*\"전쟁\"')\n",
            "(8, '0.047*\"철수\" + 0.037*\"안\" + 0.035*\"안철수\" + 0.022*\"대통령\" + 0.020*\"교체\" + 0.019*\"국민\" + 0.019*\"시대\"')\n",
            "(9, '0.040*\"철수\" + 0.019*\"답\" + 0.016*\"안\" + 0.015*\"수\" + 0.014*\"천안\" + 0.013*\"입장\" + 0.013*\"안철수\"')\n",
            "(10, '0.034*\"철수\" + 0.019*\"윤\" + 0.014*\"수\" + 0.009*\"생각\" + 0.009*\"말\" + 0.009*\"서울\" + 0.009*\"정책\"')\n",
            "(11, '0.015*\"권한\" + 0.014*\"여론\" + 0.014*\"구도\" + 0.013*\"대선\" + 0.013*\"철수\" + 0.011*\"서초\" + 0.011*\"조사\"')\n",
            "(12, '0.019*\"철수\" + 0.015*\"년\" + 0.013*\"문\" + 0.012*\"대\" + 0.012*\"조\" + 0.012*\"종\" + 0.011*\"12\"')\n",
            "(13, '0.043*\"철수\" + 0.034*\"안\" + 0.030*\"안철수\" + 0.022*\"민국\" + 0.022*\"대한민국\" + 0.022*\"대한\" + 0.020*\"청년\"')\n",
            "(14, '0.034*\"철수\" + 0.022*\"안\" + 0.014*\"대통령\" + 0.013*\"후보\" + 0.011*\"현장\" + 0.009*\"안철수\" + 0.009*\"씨\"')\n",
            "(15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\"')\n",
            "(16, '0.038*\"철수\" + 0.022*\"윤\" + 0.022*\"안\" + 0.020*\"안철수\" + 0.019*\"표\" + 0.016*\"홍\" + 0.016*\"종인\"')\n",
            "(17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "(18, '0.054*\"철수\" + 0.044*\"안\" + 0.044*\"안철수\" + 0.038*\"김\" + 0.028*\"뉴스\" + 0.027*\"심상\" + 0.024*\"동연\"')\n",
            "(19, '0.041*\"철수\" + 0.029*\"문화\" + 0.025*\"예술\" + 0.024*\"전당\" + 0.024*\"문화예술\" + 0.024*\"안\" + 0.022*\"안철수\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gngmC5azbSa-",
        "outputId": "71479bcb-f2d5-481e-e38c-0e5e20f06429"
      },
      "source": [
        "print(ldamodel.print_topics())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\" + 0.015*\"일\" + 0.014*\"11\" + 0.013*\"대통령\"'), (1, '0.033*\"철수\" + 0.030*\"특검\" + 0.025*\"안\" + 0.022*\"안철수\" + 0.021*\"쌍\" + 0.017*\"쌍특검\" + 0.017*\"경제\" + 0.014*\"국민\" + 0.013*\"뉴스\" + 0.012*\"동\"'), (2, '0.030*\"철수\" + 0.025*\"국\" + 0.020*\"윤\" + 0.016*\"힘\" + 0.013*\"후보\" + 0.013*\"당\" + 0.012*\"문\" + 0.012*\"때\" + 0.011*\"안\" + 0.011*\"민주당\"'), (3, '0.017*\"철수\" + 0.016*\"양보\" + 0.016*\"정치\" + 0.015*\"우리\" + 0.015*\"21\" + 0.013*\"거\" + 0.012*\"때문\" + 0.012*\"수\" + 0.011*\"때\" + 0.010*\"말\"'), (4, '0.023*\"철수\" + 0.022*\"안\" + 0.021*\"안철수\" + 0.011*\"속\" + 0.008*\"수능\" + 0.008*\"1\" + 0.007*\"검찰\" + 0.007*\"렬\" + 0.007*\"현재\" + 0.007*\"20\"'), (5, '0.022*\"철수\" + 0.015*\"너\" + 0.009*\"새끼\" + 0.008*\"수면\" + 0.007*\"동안\" + 0.006*\"나\" + 0.006*\"그\" + 0.005*\"64\" + 0.005*\"문\" + 0.004*\"반\"'), (6, '0.017*\"철수\" + 0.015*\"안\" + 0.012*\"3\" + 0.012*\"안철수\" + 0.010*\"청년공약\" + 0.010*\"데일리\" + 0.010*\"대선\" + 0.009*\"이재명\" + 0.009*\"후보\" + 0.009*\"지원금\"'), (7, '0.023*\"철수\" + 0.016*\"킹\" + 0.015*\"1\" + 0.014*\"루\" + 0.014*\"루킹\" + 0.013*\"기술\" + 0.012*\"전쟁\" + 0.012*\"패권\" + 0.011*\"안\" + 0.010*\"301411\"'), (8, '0.047*\"철수\" + 0.037*\"안\" + 0.035*\"안철수\" + 0.022*\"대통령\" + 0.020*\"교체\" + 0.019*\"국민\" + 0.019*\"시대\" + 0.018*\"미래\" + 0.016*\"시대교체\" + 0.014*\"준비\"'), (9, '0.040*\"철수\" + 0.019*\"답\" + 0.016*\"안\" + 0.015*\"수\" + 0.014*\"천안\" + 0.013*\"입장\" + 0.013*\"안철수\" + 0.013*\"전\" + 0.012*\"폭침\" + 0.008*\"지지자\"'), (10, '0.034*\"철수\" + 0.019*\"윤\" + 0.014*\"수\" + 0.009*\"생각\" + 0.009*\"말\" + 0.009*\"서울\" + 0.009*\"정책\" + 0.008*\"사람\" + 0.008*\"열\" + 0.008*\"때\"'), (11, '0.015*\"권한\" + 0.014*\"여론\" + 0.014*\"구도\" + 0.013*\"대선\" + 0.013*\"철수\" + 0.011*\"서초\" + 0.011*\"조사\" + 0.009*\"이번\" + 0.009*\"보수\" + 0.008*\"여론조사\"'), (12, '0.019*\"철수\" + 0.015*\"년\" + 0.013*\"문\" + 0.012*\"대\" + 0.012*\"조\" + 0.012*\"종\" + 0.011*\"12\" + 0.010*\"부산\" + 0.009*\"10\" + 0.009*\"거\"'), (13, '0.043*\"철수\" + 0.034*\"안\" + 0.030*\"안철수\" + 0.022*\"민국\" + 0.022*\"대한민국\" + 0.022*\"대한\" + 0.020*\"청년\" + 0.016*\"공약\" + 0.016*\"버스\" + 0.014*\"1\"'), (14, '0.034*\"철수\" + 0.022*\"안\" + 0.014*\"대통령\" + 0.013*\"후보\" + 0.011*\"현장\" + 0.009*\"안철수\" + 0.009*\"씨\" + 0.008*\"철수후보\" + 0.008*\"나라\" + 0.007*\"하나\"'), (15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\" + 0.013*\"다음\" + 0.012*\"후보\" + 0.012*\"완주\"'), (16, '0.038*\"철수\" + 0.022*\"윤\" + 0.022*\"안\" + 0.020*\"안철수\" + 0.019*\"표\" + 0.016*\"홍\" + 0.016*\"종인\" + 0.014*\"김\" + 0.012*\"국민\" + 0.011*\"열\"'), (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\" + 0.018*\"3\" + 0.018*\"심상\" + 0.017*\"대선\"'), (18, '0.054*\"철수\" + 0.044*\"안\" + 0.044*\"안철수\" + 0.038*\"김\" + 0.028*\"뉴스\" + 0.027*\"심상\" + 0.024*\"동연\" + 0.024*\"김동연\" + 0.023*\"힘\" + 0.018*\"여지\"'), (19, '0.041*\"철수\" + 0.029*\"문화\" + 0.025*\"예술\" + 0.024*\"문화예술\" + 0.024*\"전당\" + 0.024*\"안\" + 0.022*\"안철수\" + 0.019*\"정권\" + 0.016*\"문\" + 0.016*\"재인\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2owHzW7O4GEI"
      },
      "source": [
        "# 문서 관점에서 topic과 document 알기(문서별 토픽 분포 보기)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjexNJZ8zIpA"
      },
      "source": [
        "토픽별 단어 분포는 위에서 확인하였음. 문서별 토픽 분포에 대해 확인을 위해 이미 훈련된 LDA모델인 ldamodel[]에 전체 데이터가 정수 인코딩 된 결과를 넣은 후 확인 가능. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omKnx6dfzfeN"
      },
      "source": [
        "상위 5개의 문서에 대해서만 토픽분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-NcMoqZg-z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bdbde6-6d90-4c64-f652-0bd2a46a2dee"
      },
      "source": [
        "for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "    if i==5:\n",
        "        break\n",
        "    print(i,'번째 문서의 topic 비율은',topic_list)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 문서의 topic 비율은 [(0, 0.9660714)]\n",
            "1 번째 문서의 topic 비율은 [(9, 0.6999576), (11, 0.2400424)]\n",
            "2 번째 문서의 topic 비율은 [(1, 0.10194627), (2, 0.110027075), (3, 0.08709738), (16, 0.176246), (17, 0.46699095)]\n",
            "3 번째 문서의 topic 비율은 [(0, 0.025), (1, 0.025), (2, 0.025), (3, 0.025), (4, 0.025), (5, 0.025), (6, 0.025), (7, 0.025), (8, 0.52500004), (9, 0.025), (10, 0.025), (11, 0.025), (12, 0.025), (13, 0.025), (14, 0.025), (15, 0.025), (16, 0.025), (17, 0.025), (18, 0.025), (19, 0.025)]\n",
            "4 번째 문서의 topic 비율은 [(16, 0.9269231)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EP7ytG_fzmw4"
      },
      "source": [
        "위의 출력 결과에서 (숫자, 확률)은 토픽 번호와 해당토픽이 해당문서에서 차지하는 분포도를 의미.예를 들어 2번째 문서의 토픽 비율에서 (5, 0.16109002)은 5번 토픽이 16%의 분포도를 가지는 것을 의미"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyb5A86Nz7x1"
      },
      "source": [
        "좀 더 깔끔한 형태의 데이터프레임 형식으로 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TG7XBkDdZLN"
      },
      "source": [
        "def make_topictable_per_doc(ldamodel, corpus):\n",
        "    topic_table = pd.DataFrame()\n",
        "\n",
        "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
        "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
        "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
        "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
        "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \n",
        "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
        "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
        "\n",
        "        # 모든 문서에 대해서 각각 아래를 수행\n",
        "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
        "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
        "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
        "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
        "            else:\n",
        "                break\n",
        "    return(topic_table)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ZNzr7sYJpiCg",
        "outputId": "1d393482-a1c2-419f-fb9e-88068db4a3f0"
      },
      "source": [
        "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
        "topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\n",
        "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
        "topictable[:10]#상위 10개 댓글별 비중이 높은 토픽은 무엇이고 얼만큼 차지하는지"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문서 번호</th>\n",
              "      <th>가장 비중이 높은 토픽</th>\n",
              "      <th>가장 높은 토픽의 비중</th>\n",
              "      <th>각 토픽의 비중</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9661</td>\n",
              "      <td>[(0, 0.9660714)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>[(9, 0.6999624), (11, 0.24003766)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4671</td>\n",
              "      <td>[(1, 0.101880185), (2, 0.10990941), (3, 0.0870...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.5250</td>\n",
              "      <td>[(0, 0.025), (1, 0.025), (2, 0.025), (3, 0.025...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.9269</td>\n",
              "      <td>[(16, 0.9269231)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.6915</td>\n",
              "      <td>[(10, 0.2676131), (11, 0.6914778)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.5815</td>\n",
              "      <td>[(1, 0.041611012), (8, 0.58145785), (13, 0.238...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.8301</td>\n",
              "      <td>[(14, 0.8301171), (18, 0.094882905)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.5064</td>\n",
              "      <td>[(13, 0.41173482), (16, 0.506447)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>[(10, 0.16172521), (15, 0.7097034)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   문서 번호  ...                                           각 토픽의 비중\n",
              "0      0  ...                                   [(0, 0.9660714)]\n",
              "1      1  ...                 [(9, 0.6999624), (11, 0.24003766)]\n",
              "2      2  ...  [(1, 0.101880185), (2, 0.10990941), (3, 0.0870...\n",
              "3      3  ...  [(0, 0.025), (1, 0.025), (2, 0.025), (3, 0.025...\n",
              "4      4  ...                                  [(16, 0.9269231)]\n",
              "5      5  ...                 [(10, 0.2676131), (11, 0.6914778)]\n",
              "6      6  ...  [(1, 0.041611012), (8, 0.58145785), (13, 0.238...\n",
              "7      7  ...               [(14, 0.8301171), (18, 0.094882905)]\n",
              "8      8  ...                 [(13, 0.41173482), (16, 0.506447)]\n",
              "9      9  ...                [(10, 0.16172521), (15, 0.7097034)]\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdefHJqG21K8"
      },
      "source": [
        "# 단어 관점에서topic과 documents를 알기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1SlwAhmkhi-",
        "outputId": "9c63f043-6ca3-4b5b-a316-86314b4c706f"
      },
      "source": [
        "keyword=\"과학기술\"\n",
        "id_list=[]\n",
        "for i in range(len(data)):\n",
        "  if keyword in tokenized_doc[i]:\n",
        "    print(\"해당 단어가 들어간 댓글:\",i,\"번 댓글\",\":\",data['tweet'][i])\n",
        "    for y in range(len(tokenized_doc[i])):\n",
        "      if tokenized_doc[i][y]==keyword:\n",
        "        key_id=corpus[i][y]\n",
        "        print(\"해당단어의 아이디는\",key_id)\n",
        "        id_list.append(key_id[0])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "해당 단어가 들어간 댓글: 729 번 댓글 : 미국의 케네디대통령은 달착륙을 비전으로 내세웠고 바이든대통령은 과학 반도체 강국을 비전으로 내세웠습니다 나라의 부흥은 과학기술이 뒷받침되어야 합니다 안철수후보가 바로 그런 사람입니다 우리나라의 부흥은 박정희 김대중을 거치며 도약했습니다 \n",
            "해당단어의 아이디는 (3462, 1)\n",
            "해당 단어가 들어간 댓글: 941 번 댓글 : 나 KBS 심야토론 문자 여러번 보냈는데 오늘 처음 나왔어요 이제 대한민국도 과학자 출신 대통령이 나와야 세계로 뛸 수 있다 안철수 과학기술 G5\n",
            "해당단어의 아이디는 (4186, 1)\n",
            "해당 단어가 들어간 댓글: 1363 번 댓글 : 과학기술의 세계적인 발전방향을 알고 미리 대처할 수 있는 대통령 이 꼭 필요한 때입니다 저 안철수가 걸어 온 길 다시 한 번 지켜봐 주십시오 안철수 20211118 4weJG6PMFx\n",
            "해당단어의 아이디는 (16, 1)\n",
            "해당 단어가 들어간 댓글: 1366 번 댓글 : 저의 제1호 공약은 남들이 따라올 수 없는 초격차 과학기술 5개를 확보하면 삼성전자 급의 글로벌 대기업 5개를 만들 수 있고 우리는 세계 5대 경제 강국에 진입할 수 있다는 내용입니다 저는 이러한 국가전략산업을 지역이 주도하게 하겠습니다 안철수 20211118 2WWzwp6ce9\n",
            "해당단어의 아이디는 (464, 1)\n",
            "해당 단어가 들어간 댓글: 1412 번 댓글 :  안철수 lt SBS D포럼 5천만의 소리 지휘자를 찾습니다 gt ECUfiJqFYu 세계 대전환기인 지금 대한민국의 미래 국가 전략은 과학기술중심 국가가 되어야 합니다 과학기술의 세계적인 발전방향을 알고 미리 대처할 수 있는 대통령 이 꼭 필요한 때입니다 rZiZRgnODm\n",
            "해당단어의 아이디는 (1235, 1)\n",
            "해당 단어가 들어간 댓글: 1617 번 댓글 : 과거 vs 미래 세계 vs 대한민국 과학기술 중심 진짜교체_ 시대교체 2022년 새로운 변화를 향한 국민의 혁신적 선택 국민의당 안철수 가 국민과 함께 새로운 시대를 연다 \n",
            "해당단어의 아이디는 (91, 1)\n",
            "해당 단어가 들어간 댓글: 1731 번 댓글 :  안철수 장차 우리나라가 나아가야 할 길은 이러한 초격차 과학기술 분야를 5개 확보하는 것이며 그 중 하나를 제약 바이오 산업으로 생각하고 있다 라며 이러한 시기에 중요한 산업을 제대로 발전시키는 것이 정부의 역할이다 On2kCb4d72\n",
            "해당단어의 아이디는 (203, 1)\n",
            "해당 단어가 들어간 댓글: 1759 번 댓글 :  안철수 세계 대전환기인 지금 대한민국의 미래 국가 전략은 과학기술중심 국가가 되어야 합니다 과학기술의 세계적인 발전방향을 알고 미리 대처할 수 있는 대통령 이 꼭 필요한 때입니다 SBS D포럼 asIb7uVKcy\n",
            "해당단어의 아이디는 (591, 1)\n",
            "해당 단어가 들어간 댓글: 1945 번 댓글 :  과학기술이 안보와 경제에 직결되고 있다 지정학 geo political 에서 기정학 techno political 으로 급속히 변환되고 있다 과학기술계 공동성명과 안철수 후보의 초격차 기업 육성론 을 계기로 과학기술 및 산업 전략과 비전을 둘러싼 경쟁이 시작되었다 HzZVZM20sU\n",
            "해당단어의 아이디는 (9, 1)\n",
            "해당 단어가 들어간 댓글: 1965 번 댓글 : 과학기술 대통령 초격차기술 가즈아 안철수 yykIZ4VeRl\n",
            "해당단어의 아이디는 (16, 1)\n",
            "해당 단어가 들어간 댓글: 2039 번 댓글 : 국민의당 천안시을 지역위원회 위원장 결정 RsogUYfJkw 신순옥 위원장 안철수 후보의 어묵을 먹는 사진을 찍는 모습이 아니라 과학기술 대통령을 표방하는 미래의 먹거리를 양성하는 차별성을 강조하는 공약 등을 강조해 내년 대선 필승을 위해 최선을 다하겠다 감사합니다 \n",
            "해당단어의 아이디는 (2716, 1)\n",
            "해당 단어가 들어간 댓글: 2169 번 댓글 :  안철수 lt SBS D포럼 5천만의 소리 지휘자를 찾습니다 gt 발언 세계 대전환기인 지금 대한민국의 미래 국가 전략은 과학기술중심 국가가 되어야 합니다 과학기술의 세계적인 발전방향을 알고 미리 대처할 수 있는 대통령 이 꼭 필요한 때입니다 F1nPSnt9DH\n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 2498 번 댓글 :  kjd5679rest monica_doh 예 역시 과학기술 대통령감과 이닌 분의 큰 차이입니다 \n",
            "해당단어의 아이디는 (591, 1)\n",
            "해당 단어가 들어간 댓글: 2542 번 댓글 : 안철수의 SMR공약은 누구든 베낄 수 있겠지만 안철수가 설립한 동그라미 재단을 통해 SMR 개발을 지원해 온 까지는 복사할 수 없는 것 아닌가 사람들은 여기서도 각 후보자들의 과학기술에 대한 실력 미래에 대한 예측능력 대한민국을 위한 추진력을 누가 제대로 갖췄는지 판단할 수 있다 \n",
            "해당단어의 아이디는 (1094, 1)\n",
            "해당 단어가 들어간 댓글: 2818 번 댓글 :  이런 후보 또 없습니다 과학기술 대통령 우리가 꿈꾸는 능력과 리더쉽과 인성이 뛰어난 사람 그는 안철수\n",
            "해당단어의 아이디는 (16, 1)\n",
            "해당 단어가 들어간 댓글: 2876 번 댓글 : 얘 뭔지 알까 버츄얼휴먼 로지 가상인간임 광고 찍고 팬서비스하고 드라마 할 예정인데 이재명 윤석열은 관련법 규제 철회 및 법개정 기술지원등 할 수 있을까 행동하는거나 생각하는거 보면 구시대적인 발상만 하던데 지금은 과학기술 대통령이 필요할 때임 안철수 PsbhXZRvPE xEmvOptUV6\n",
            "해당단어의 아이디는 (9178, 1)\n",
            "해당 단어가 들어간 댓글: 2963 번 댓글 : 포토존에서 내가 선택한 안철수 포스터 준비된 미래 시대교체 안철수 과학기술 대통령이 되길 응원합니다 메타버스 들어가는 곳 DxJoRFpDeE 안철수 시대교체 과학기술대통령 eZKJKB3azu\n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 3032 번 댓글 : 뭘 아는 안철수 대표말고 누가 있는가 의지가 있다던 문재인이 뭘 했는가 과학적으로 생각한다면 답은 분명히 보일 것이다 안 철 수 과기단체들 차기대통령 과학기술 중심 비전 보여야 이재명 윤석열 심상정 안철수 캠프 성명서 전달 동아사이언스 s2ASSpqCzP\n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 3152 번 댓글 : 아바타들 보소 안철수 후보님과 기자님들 너무 귀여워 자주 해주세요 새롭네요 국민의당 안철수 메타버스 기자간담회 안철수후보 메타버스 기자간담회 과학기술 MoneyS E3xFyfBkQT MKYkcGj1P6\n",
            "해당단어의 아이디는 (4681, 1)\n",
            "해당 단어가 들어간 댓글: 3179 번 댓글 :  안철수 님이 쏘아올린 공이네요 과학단체 에서 과학기술 국가비전 보여주라고 성명내었네요 이번 대통령은 과학기술_국가비전 이 확실한 사람을 선택해야함 과학기술 6개 단체 공동 성명 대선후보자들 과학기술 국가 비전 보여줘야 출처 이데일리 c6nAOJnPYp dAQSeh2kG2\n",
            "해당단어의 아이디는 (152, 1)\n",
            "해당 단어가 들어간 댓글: 3214 번 댓글 : 그러니까 죽음 직전까지 내몰린 자영업자들 안철수는 도울 계획이 전혀 없다는거죠 과학기술이란건 투자를 아무리 해도 급속히 그 결과가 나오는 쪽이 아닌데 그쪽에는 무한정 퍼붓겠다는거구요 물론 그런다고 삼성급 기업이 나온다는 보장도 없구요\n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 3221 번 댓글 :  안철수 과학기술 G5경제강국 도약시킬 것 시대교체 준비된미래 0gKm2k40Qp 출처 YouTube\n",
            "해당단어의 아이디는 (62, 1)\n",
            "해당 단어가 들어간 댓글: 3248 번 댓글 :  7nYJVktPbz 과학기술 5G강국 도약 시킬것 안철수 국민의당 \n",
            "해당단어의 아이디는 (17, 1)\n",
            "해당 단어가 들어간 댓글: 3263 번 댓글 : G5 도약 위한 청사진은 과학기술 부총리를 신설하고 청와대 과학기술 담당을 수석비서관급으로 격상하는 정부조직 개편이 필요하다 초격차 과학기술 관련 위원회도 만들어야 한다 현재 정부 연구개발 R amp D 예산의 문제점은 성공률이 98 라는 점이다 될 수 있는 사업에게만 투자를 한다 안철수\n",
            "해당단어의 아이디는 (62, 1)\n",
            "해당 단어가 들어간 댓글: 3350 번 댓글 : 과학기술을 육성해 G5에 들어가겠다 이게 과학기술 전문가라는 안철수의 말이다 한국이 일본 수준으로 과학기술을 끌어올리려고 해도 정말 꾸준히 20년 이상은 투자를 해야 겨우 효과가 나올까 말까 한 일인데 그걸 한 대통령 임기에 한다고 하면 그건 사기야 \n",
            "해당단어의 아이디는 (9, 1)\n",
            "해당 단어가 들어간 댓글: 3356 번 댓글 : 제 20대 대통령 선거에 국민의당 안철수 후보를 지지합니다 국민의당 안철수 후보를 지지선언하며 대한민국의 과학기술 혁명과 시대교체의 지도자이며 과학기술 혁명과 시대교체를 이루며 의료봉사로 헌신하시고 전염병의 위기상황속에서도 국민의 생명과 안전을 지키는 후보이기에 지지할 것입니다 \n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 3359 번 댓글 : 제 20대 대통령 선거에 국민의당 안철수 후보를 지지합니다 국민의당 안철수 후보를 지지선언하며 대한민국의 과학기술 혁명과 시대교체의 지도자이며 과학기술 혁명과 시대교체를 이루며 의료봉사로 헌신하시고 전염병의 위기상황속에서도 국민의 생명과 안전을 지키는 후보이기에 지지선언합니다 \n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 3529 번 댓글 :  현장 동영상 과학기술 G5경제강국 도약시킬 것 시대교체 준비된미래 GJwwFVVEUg\n",
            "해당단어의 아이디는 (297, 1)\n",
            "해당 단어가 들어간 댓글: 3536 번 댓글 :  안철수 과학기술 G5경제강국 도약시킬 것 시대교체 준비된미래 q3KmjCIgZn via YouTube\n",
            "해당단어의 아이디는 (62, 1)\n",
            "해당 단어가 들어간 댓글: 3852 번 댓글 : 준비된 대통령 안철수 지도자로서 갖추어야 할 도덕성 판단력 미래를 내다보는 예측력 결단력 통합의 리더십과 경제 안보 과학기술 능력과 글로벌 감각을 지닌 외교능력과 외국어 능통까지 이 정도면 최고 아님 \n",
            "해당단어의 아이디는 (2542, 1)\n",
            "해당 단어가 들어간 댓글: 3921 번 댓글 : 안철수 법률가 대통령 되는 시대 아냐 과학기술 대통령 필요 Byblo4Sggx 철수형은 다음에 지금은 법치의 정치화로 법치주의가 무너졌으니 이를 바로 잡는게 먼저요 적임자는 석열이형 석열이형이 좌익파쇼들이 저지른 자갈길을 정리하여 고속도로 만들어 놓으면 다음은 철수형이 \n",
            "해당단어의 아이디는 (268, 1)\n",
            "해당 단어가 들어간 댓글: 4085 번 댓글 :  과학계 원로 만난 안철수 李 尹 겨냥 법률가 지도자 안 돼 과학기술 立國 통한 제2 한강의 기적 만들어야 wPD8xecGMY\n",
            "해당단어의 아이디는 (2807, 1)\n",
            "해당 단어가 들어간 댓글: 4118 번 댓글 : Instagram 데일리안 안철수 산업화 민주화 다음은 과학기술 선진화 내가 가장 잘 할 수 있다 BdXXzIlZ7k\n",
            "해당단어의 아이디는 (2025, 1)\n",
            "해당 단어가 들어간 댓글: 4132 번 댓글 : 안철수 법률가 대통령 되는 시대 아냐 과학기술 대통령 필요 출처 디지털타임스 네이버 뉴스 hl5FfQyYxQ\n",
            "해당단어의 아이디는 (457, 1)\n",
            "해당 단어가 들어간 댓글: 4150 번 댓글 : 4류 구태정치 패거리들의 칠푼이 팔푼이같은 대통령들을 뽑아 허구헌날 병신짓만 하다 성장동력은 바닥났고 나라가 10년은 거꾸로 갔다 이제 더 이상 그런 병신같은 짓을 반복해선 안된다 안철수 제2의 과학기술 입국으로 제2 한강의 기적 만들 것 출처 뉴시스 zPuUhy3pHO\n",
            "해당단어의 아이디는 (6013, 1)\n",
            "해당 단어가 들어간 댓글: 4186 번 댓글 : 안철수 제2의 과학기술 입국으로 제2 한강의 기적 만들 것 출처 뉴시스 네이버 뉴스 o6YTi5j0rF 전 세계 과학기술 패권 전쟁 중 법률가 지도자는 못해 준비된미래 시대교체 안철수대통령\n",
            "해당단어의 아이디는 (150, 1)\n",
            "해당 단어가 들어간 댓글: 4187 번 댓글 : 안철수 과학기술 대통령 필요 bopsYT7hUz 서울 뉴스1 국회사진취재단 14일 서초동의 한 중식당에서 안철수 국민의당 대선후보가 김두철 전 기초과학연구원 원장 신용현 전 한국표준과학연구원 원장 만나 인사를 나누고 있다 2021 11 14 뉴스1 준비된미래 시대교체 안철수대통령 ARe0PHKTGc\n",
            "해당단어의 아이디는 (26, 1)\n",
            "해당 단어가 들어간 댓글: 4201 번 댓글 : 안철수 제2의 과학기술 입국으로 제2 한강의 기적 만들 것 뉴시스 OmOfUUCjPJ\n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 4203 번 댓글 : 안철수 세계는 과학기술 전쟁 중 법률가에 나라 맡길 수 없어 MToday t8ANjDQe6a\n",
            "해당단어의 아이디는 (152, 1)\n",
            "해당 단어가 들어간 댓글: 4208 번 댓글 : 안철수 제2의 과학기술 입국으로 제2 한강의 기적 만들 것 다음 뉴스 uuAtPT5so5\n",
            "해당단어의 아이디는 (705, 1)\n",
            "해당 단어가 들어간 댓글: 4252 번 댓글 : 안철수 대선 완주할것 과학기술 대통령 나올때 됐다 李 尹 빨리 쌍특검 시행해 국민 의혹 풀어야 이준석 겨냥 당권 갖고 있지 않아 신경 안써 제3지대 공통 정책이 있으면 공조할 수 있어 EzPmy9OC24\n",
            "해당단어의 아이디는 (189, 1)\n",
            "해당 단어가 들어간 댓글: 4261 번 댓글 : 초격차 과학기술 대통령 달려 가즈아 신용현 전 한국표준과학연구원장 만난 안철수 대표 출처 노컷뉴스 네이버 뉴스 sQlBj0pmcz\n",
            "해당단어의 아이디는 (26, 1)\n",
            "해당 단어가 들어간 댓글: 4269 번 댓글 :  안철수 세계는 과학기술 패권 3차 대전 중 BZC8XHAwri 안 후보는 이날 페이스북에 과학기술이 곧 국력이고 주권이며 민생이고 복지로 과학기술은 이제 먹고 사는 문제가 아니라 죽고 사는 문제 라며 이같이 밝혔다 \n",
            "해당단어의 아이디는 (123, 1)\n",
            "해당 단어가 들어간 댓글: 4274 번 댓글 : 더이상 법조 기술자들이 나라를 반토막 내고 후려치는 거 못봐주겠다 안철수 법률가 대통령 되는 시대 아냐 과학기술 대통령 필요 출처 디지털타임스 네이버 뉴스 iw4k37Qobi\n",
            "해당단어의 아이디는 (1104, 1)\n",
            "해당 단어가 들어간 댓글: 4283 번 댓글 : 김두철 전 기초과학연구 원장과 오찬 안철수 국민의당 기초과학 미래담론 시대교체 G5강국 과학기술 국민상자 위드안 jnDXyKQz2G\n",
            "해당단어의 아이디는 (6350, 1)\n",
            "해당 단어가 들어간 댓글: 4285 번 댓글 : 안철수 법률가 대통령 되는 시대 아냐 과학기술 대통령 필요 다음 뉴스 U5nKvOxuSh\n",
            "해당단어의 아이디는 (506, 1)\n",
            "해당 단어가 들어간 댓글: 4364 번 댓글 : 안철수 세계는 과학기술 패권전쟁 중 법률가들에 나라 못 맡긴다 21세기에 필요한 리더십은 글로벌 감각을 갖추고 과학기술의 흐름을 주도하는 리더십이어야 한다 BWTAdryPQJ\n",
            "해당단어의 아이디는 (196, 1)\n",
            "해당 단어가 들어간 댓글: 4395 번 댓글 : 안철수는 G5 설계자 555공약 내건 안철수 박정희는 산업화 김대중은 정보화 5가지 초격차 과학기술 5개의 삼성급 글로벌대기업으로 5대 경제강국에 진입한단 비전 출처 헤럴드경제 네이버 뉴스 fi338OUMkg\n",
            "해당단어의 아이디는 (2532, 1)\n",
            "해당 단어가 들어간 댓글: 4397 번 댓글 :  댓글들 좋아 안철수 세계는 과학기술 패권전쟁 중 법률가들에 나라 못 맡긴다 출처 뉴스1 네이버 뉴스 DU2lZ427Z7\n",
            "해당단어의 아이디는 (505, 1)\n",
            "해당 단어가 들어간 댓글: 4401 번 댓글 : 국내외 상황도 안철수의 시간을 말하고 있습니다 과학기술 패권전쟁에 대한 식견 다자정상외교에 필요한 글로벌 감각과 영어회화 양당의 후보 미비 문명사적 전환과 팬데믹\n",
            "해당단어의 아이디는 (346, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dFGflia1p_V",
        "outputId": "63cf5f5a-0764-4ddd-fa3d-3a8f1c28a2de"
      },
      "source": [
        "# 과학기술에 관련된 토픽(+토픽에 영향주는 키워드) 찾기\n",
        "term_topic_dist = ldamodel.get_term_topics(1731, minimum_probability=0)\n",
        "sorted_term_topic = sorted(term_topic_dist, key=lambda x:x[1], reverse=True)\n",
        "sorted_term_topic"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(13, 0.00078898104)]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj-Lmlv2Mulj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f865326-751c-4294-d8f5-a3cc765fa492"
      },
      "source": [
        "topics[13]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,\n",
              " '0.043*\"철수\" + 0.034*\"안\" + 0.030*\"안철수\" + 0.022*\"민국\" + 0.022*\"대한민국\" + 0.022*\"대한\" + 0.020*\"청년\"')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wItx2jNhyr_L",
        "outputId": "9e3c94ca-69c2-4984-cc8f-3df4396c0ff6"
      },
      "source": [
        "for n in range(len(id_list)):\n",
        "  term_topic_dist = ldamodel.get_term_topics(id_list[n], minimum_probability=0)\n",
        "  sorted_term_topic = sorted(term_topic_dist, key=lambda x:x[1], reverse=True)\n",
        "  print(\"토픽중요도:\",round(int(sorted_term_topic[0][1]*100),2),\"%\",\"토픽번호 및 해당키워드중요도:\",topics[sorted_term_topic[0][0]])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (9, '0.040*\"철수\" + 0.019*\"답\" + 0.016*\"안\" + 0.015*\"수\" + 0.014*\"천안\" + 0.013*\"입장\" + 0.013*\"안철수\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (7, '0.023*\"철수\" + 0.016*\"킹\" + 0.015*\"1\" + 0.014*\"루\" + 0.014*\"루킹\" + 0.013*\"기술\" + 0.012*\"전쟁\"')\n",
            "토픽중요도: 7 % 토픽번호 및 해당키워드중요도: (15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 2 % 토픽번호 및 해당키워드중요도: (13, '0.043*\"철수\" + 0.034*\"안\" + 0.030*\"안철수\" + 0.022*\"민국\" + 0.022*\"대한민국\" + 0.022*\"대한\" + 0.020*\"청년\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (3, '0.017*\"철수\" + 0.016*\"양보\" + 0.016*\"정치\" + 0.015*\"우리\" + 0.015*\"21\" + 0.013*\"거\" + 0.012*\"때문\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (18, '0.054*\"철수\" + 0.044*\"안\" + 0.044*\"안철수\" + 0.038*\"김\" + 0.028*\"뉴스\" + 0.027*\"심상\" + 0.024*\"동연\"')\n",
            "토픽중요도: 2 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 7 % 토픽번호 및 해당키워드중요도: (15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (18, '0.054*\"철수\" + 0.044*\"안\" + 0.044*\"안철수\" + 0.038*\"김\" + 0.028*\"뉴스\" + 0.027*\"심상\" + 0.024*\"동연\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 7 % 토픽번호 및 해당키워드중요도: (15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (18, '0.054*\"철수\" + 0.044*\"안\" + 0.044*\"안철수\" + 0.038*\"김\" + 0.028*\"뉴스\" + 0.027*\"심상\" + 0.024*\"동연\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "토픽중요도: 7 % 토픽번호 및 해당키워드중요도: (15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "토픽중요도: 2 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (8, '0.047*\"철수\" + 0.037*\"안\" + 0.035*\"안철수\" + 0.022*\"대통령\" + 0.020*\"교체\" + 0.019*\"국민\" + 0.019*\"시대\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (10, '0.034*\"철수\" + 0.019*\"윤\" + 0.014*\"수\" + 0.009*\"생각\" + 0.009*\"말\" + 0.009*\"서울\" + 0.009*\"정책\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (16, '0.038*\"철수\" + 0.022*\"윤\" + 0.022*\"안\" + 0.020*\"안철수\" + 0.019*\"표\" + 0.016*\"홍\" + 0.016*\"종인\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (6, '0.017*\"철수\" + 0.015*\"안\" + 0.012*\"3\" + 0.012*\"안철수\" + 0.010*\"청년공약\" + 0.010*\"데일리\" + 0.010*\"대선\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (2, '0.030*\"철수\" + 0.025*\"국\" + 0.020*\"윤\" + 0.016*\"힘\" + 0.013*\"후보\" + 0.013*\"당\" + 0.012*\"문\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (10, '0.034*\"철수\" + 0.019*\"윤\" + 0.014*\"수\" + 0.009*\"생각\" + 0.009*\"말\" + 0.009*\"서울\" + 0.009*\"정책\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (15, '0.080*\"철수\" + 0.079*\"안\" + 0.078*\"안철수\" + 0.035*\"뉴스\" + 0.022*\"출처\" + 0.020*\"네이버\" + 0.018*\"대선\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n",
            "토픽중요도: 3 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (2, '0.030*\"철수\" + 0.025*\"국\" + 0.020*\"윤\" + 0.016*\"힘\" + 0.013*\"후보\" + 0.013*\"당\" + 0.012*\"문\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (8, '0.047*\"철수\" + 0.037*\"안\" + 0.035*\"안철수\" + 0.022*\"대통령\" + 0.020*\"교체\" + 0.019*\"국민\" + 0.019*\"시대\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (14, '0.034*\"철수\" + 0.022*\"안\" + 0.014*\"대통령\" + 0.013*\"후보\" + 0.011*\"현장\" + 0.009*\"안철수\" + 0.009*\"씨\"')\n",
            "토픽중요도: 0 % 토픽번호 및 해당키워드중요도: (0, '0.038*\"철수\" + 0.034*\"안\" + 0.032*\"안철수\" + 0.031*\"과학\" + 0.029*\"기술\" + 0.018*\"과학기술\" + 0.016*\"5\"')\n",
            "토픽중요도: 1 % 토픽번호 및 해당키워드중요도: (17, '0.052*\"윤\" + 0.040*\"이재명\" + 0.039*\"열\" + 0.039*\"철수\" + 0.022*\"심상정\" + 0.019*\"4\" + 0.018*\"후보\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf29AxQFzqyI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}